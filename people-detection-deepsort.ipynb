{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c6aa09b-f215-476d-9b49-5927c9c4d6a7",
   "metadata": {},
   "source": [
    "# People Detection Tracking (YOLOv8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552adc8a-9cf1-4943-bf1e-2817a22cc725",
   "metadata": {},
   "source": [
    "## Download YOLOv8 wright\n",
    "\n",
    "This notebook requires YOLOv8 weight. Please download YOLOv8 weight from Ultralytics as `yolov8n.pt`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33a3f21-068b-45be-8de8-a95e1bb64f11",
   "metadata": {},
   "source": [
    "## Get up and running\n",
    "\n",
    "Get frames, draw boundary boxes and with OpenCV, YOLO as detection, and DeepSORT for tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3289a6e-885e-4da7-bc7a-3d5dc1f7b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import cv2\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import numpy as np\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2487d1cb-196e-47b1-8300-2743a3f477d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')  # load pretrained yolov8 wight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f031c384-1b98-40ec-a95d-b15fd6efbcfe",
   "metadata": {},
   "source": [
    "Either download a video to inference or stream from a webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64931366-ba70-47d3-a3a3-cd4d1c66194a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=14n0an0gxm14TJFoYKMdhv3Sz-afffAZ6\n",
      "To: C:\\Users\\Admin\\Downloads\\Workspace\\putt's works\\people-detection-tracking\\people.mp4\n",
      "\n",
      "  0%|          | 0.00/4.23M [00:00<?, ?B/s]\n",
      " 12%|#2        | 524k/4.23M [00:00<00:02, 1.47MB/s]\n",
      " 25%|##4       | 1.05M/4.23M [00:00<00:02, 1.54MB/s]\n",
      " 37%|###7      | 1.57M/4.23M [00:01<00:01, 1.38MB/s]\n",
      " 50%|####9     | 2.10M/4.23M [00:01<00:01, 1.45MB/s]\n",
      " 62%|######1   | 2.62M/4.23M [00:01<00:01, 1.51MB/s]\n",
      " 74%|#######4  | 3.15M/4.23M [00:02<00:00, 1.54MB/s]\n",
      " 87%|########6 | 3.67M/4.23M [00:02<00:00, 1.55MB/s]\n",
      " 99%|#########9| 4.19M/4.23M [00:02<00:00, 1.58MB/s]\n",
      "100%|##########| 4.23M/4.23M [00:02<00:00, 1.53MB/s]\n"
     ]
    }
   ],
   "source": [
    "# from file\n",
    "!gdown 14n0an0gxm14TJFoYKMdhv3Sz-afffAZ6\n",
    "cap = cv2.VideoCapture(\"people.mp4\")\n",
    "\n",
    "# from webcam\n",
    "# cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780cd973-aa81-4527-a55e-8594fbbb1568",
   "metadata": {},
   "source": [
    "Initialize DeepSORT tracker for tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "060d157c-8338-47fd-a5fc-113852526ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs: https://pypi.org/project/deep-sort-realtime/\n",
    "tracker = DeepSort()  # initialize deep sort (tracker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a804bd70-548a-450d-ae38-c77e2843c933",
   "metadata": {},
   "source": [
    "Randomize tracked object if not recognize, otherwise random a color for each tracked object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0451887d-d476-44cf-a238-aad8ea71dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_color(colors, track_id):\n",
    "    \"\"\"If tracked object is exists, use the existed color, otherwise random a color for each tracked object\"\"\"\n",
    "    if not track_id in colors:\n",
    "        colors[track_id] = (\n",
    "            random.randint(0, 255),\n",
    "            random.randint(0, 255),\n",
    "            random.randint(0, 255)\n",
    "        )\n",
    "    return colors[track_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928523fc-e6b4-42c7-90d9-e387cc87f0d2",
   "metadata": {},
   "source": [
    "Get each from video capture, save all bounding boxes, classes, and confidence (with 50% threshold), and track with DeepSORT, then draw each corresponding object from the tracker to the image.\n",
    "After the video capture is closed whether it's streamed all contents or stopped by the user's input, releases the video capture resource and destroy all OpenCV's windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e4e5806-9125-4277-a8aa-55bdcf75daca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 22 persons, 2 birds, 76.3ms\n",
      "Speed: 3.7ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 2 birds, 62.3ms\n",
      "Speed: 2.0ms preprocess, 62.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 2 birds, 71.9ms\n",
      "Speed: 3.1ms preprocess, 71.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 2 birds, 58.8ms\n",
      "Speed: 2.0ms preprocess, 58.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 2 birds, 56.0ms\n",
      "Speed: 1.0ms preprocess, 56.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 2 birds, 58.1ms\n",
      "Speed: 1.5ms preprocess, 58.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 2 birds, 62.3ms\n",
      "Speed: 2.0ms preprocess, 62.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 2 birds, 72.1ms\n",
      "Speed: 3.0ms preprocess, 72.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 2 birds, 69.8ms\n",
      "Speed: 2.0ms preprocess, 69.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 2 birds, 76.9ms\n",
      "Speed: 1.5ms preprocess, 76.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 2 birds, 58.1ms\n",
      "Speed: 2.0ms preprocess, 58.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 2 birds, 56.0ms\n",
      "Speed: 2.1ms preprocess, 56.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 2 birds, 54.8ms\n",
      "Speed: 2.0ms preprocess, 54.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 2 birds, 53.8ms\n",
      "Speed: 1.0ms preprocess, 53.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 2 birds, 54.9ms\n",
      "Speed: 1.5ms preprocess, 54.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 2 birds, 60.8ms\n",
      "Speed: 2.0ms preprocess, 60.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 2 birds, 58.6ms\n",
      "Speed: 1.0ms preprocess, 58.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 2 birds, 56.3ms\n",
      "Speed: 2.0ms preprocess, 56.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 2 birds, 59.7ms\n",
      "Speed: 2.0ms preprocess, 59.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 persons, 2 birds, 60.0ms\n",
      "Speed: 3.0ms preprocess, 60.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 1 bird, 57.9ms\n",
      "Speed: 3.0ms preprocess, 57.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 1 bird, 55.5ms\n",
      "Speed: 2.0ms preprocess, 55.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 bird, 62.3ms\n",
      "Speed: 2.0ms preprocess, 62.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 bird, 56.2ms\n",
      "Speed: 2.0ms preprocess, 56.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "user stopped the process\n"
     ]
    }
   ],
   "source": [
    "WIDTH = 2\n",
    "track_colors = {}\n",
    "\n",
    "while cap.isOpened():\n",
    "    ok, frame = cap.read()  # read frame from the video capture\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    results = model(frame, conf=0.5)\n",
    "\n",
    "    # detections contain bounding box, confidence, and class ID\n",
    "    detections = []\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()  # get bounding box\n",
    "            confidence = box.conf.cpu().numpy()\n",
    "            class_id = box.cls.cpu().numpy()\n",
    "\n",
    "            # classes: https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml\n",
    "            # 0 = person\n",
    "            if class_id != 0:\n",
    "                continue\n",
    "\n",
    "            detection = ((x1, y1, x2 - x1, y2 - y1), confidence, class_id)\n",
    "            detections.append(detection)\n",
    "\n",
    "    # update tracker with current detections\n",
    "    tracked_objs = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    for obj in tracked_objs:\n",
    "        if not obj.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        track_id = obj.track_id\n",
    "\n",
    "        # get left-top-right-bottom bounding box in integers\n",
    "        ltrb = np.array(obj.to_ltrb()).astype(np.int32)\n",
    "        x1, y1, x2, y2 = ltrb\n",
    "\n",
    "        # get color for each tracked object\n",
    "        color = get_track_color(track_colors, track_id)\n",
    "\n",
    "        # draw a bounding box to the image\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, WIDTH)\n",
    "        \n",
    "        # draw a text to the image with tracked ID\n",
    "        cv2.putText(frame, f'ID {track_id}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, WIDTH)\n",
    "\n",
    "    cv2.imshow('output', frame)\n",
    "\n",
    "    # press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print('user stopped the process')\n",
    "        break\n",
    "\n",
    "cap.release()  # release video capture resource\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f92c7ae-b87c-4ec9-85db-2be98a735dde",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
